{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 :Import Dataset\n",
    "In the code cell below, we import a dataset of actress images. We populate a few variables through the use of the load_files function from the scikit-learn library:\n",
    "\n",
    "1. train_files, valid_files, test_files - numpy arrays containing file paths to images\n",
    "2. train_targets, valid_targets, test_targets - numpy arrays containing onehot-encoded classification labels\n",
    "3. actress_names - list of string-valued dog breed names for translating labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Actress Images 4970\n",
      "Train Actress Images 3978\n",
      "Test Actress Images 496\n",
      "Valid Actress Images 496\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "\n",
    "#define function to load train, test and valid datasets\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    actress_files = np.array(data['filenames'])\n",
    "    actress_targets = np_utils.to_categorical(np.array(data['target']), 5) #As of now we have 5 actress to comapre with\n",
    "    return actress_files, actress_targets\n",
    "\n",
    "#load train,test,valid datasets\n",
    "train_files, train_targets = load_dataset('../Celebs/train')\n",
    "test_files, test_targets = load_dataset('../Celebs/test')\n",
    "valid_files, valid_targets = load_dataset('../Celebs/valid')\n",
    "\n",
    "print(\"Total Actress Images {}\".format(len(np.hstack([train_files, test_files, valid_files]))))\n",
    "print(\"Train Actress Images {}\".format(len(train_files)))\n",
    "print(\"Test Actress Images {}\".format(len(test_files)))\n",
    "print(\"Valid Actress Images {}\".format(len(valid_files)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process the data\n",
    "Here we are using tensorflow as backend for keras and it requires our images as a certain 4D array a.k.a 4D Tensor with shape.\n",
    "\n",
    "$$\n",
    "(\\text{nb_samples}, \\text{rows}, \\text{columns}, \\text{channels}),\n",
    "$$\n",
    "\n",
    "where nb_samples corresponds to the total number of images (or samples), and rows, columns, and channels correspond to the number of rows, columns, and channels for each image, respectively.\n",
    "\n",
    "The path_to_tensor takes a string spacifying file location and it does the following operation.\n",
    "\n",
    "1. Resizes the image as (224,224).\n",
    "2. Convert the squared image as an array (3d array)\n",
    "3. Expand the 3d array to 4d array as (1,224,224,3)\n",
    "\n",
    "Another helper function paths_to_tensor takes an array of image file locations as param and in turn calls path_to_tensor on all of them and then vertically stack the output.\n",
    "\n",
    "Here, nb_samples is the number of samples, or number of images, in the supplied array of image paths. It is best to think of nb_samples as the number of 3D tensors (where each 3D tensor corresponds to a different image) in your dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "    \n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]    \n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa54ae91331a43baaa0c79acfd2b5bef"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3978, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True   \n",
    "\n",
    "#pre-process the data\n",
    "train_tensors = paths_to_tensor(train_files).astype('float32')/255\n",
    "test_tensors = paths_to_tensor(test_files).astype('float32')/255\n",
    "valid_tensors = paths_to_tensor(valid_files).astype('float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "1. Create a CNN from scratch with these tensors\n",
    "2. Create Augmentations and with use of that, And create bottleneck features and save it to S3\n",
    "3. Fetch bottleneck features from S3 and use transfer learning to build a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
